{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# LiteRT\n",
    "\n",
    "You can find ready-to-run LiteRT models for a wide range of ML/AI tasks, or convert and run TensorFlow, PyTorch, and JAX models to the TFLite format using the AI Edge conversion and optimization tools.\n",
    "\n",
    "link: https://ai.google.dev/edge/litert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ai-edge-litert-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "In this section, we will explore essential aspects of working with LiteRT, focusing on three key areas:\n",
    "1. Where to Find Models\n",
    "2. Key Steps for Reducing Model Size\n",
    "3. Deploying the Model onto the Board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Ready-to-run models\n",
    "\n",
    "link: https://www.kaggle.com/models?framework=tfLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Example, downloading yolov5\n",
    "path = kagglehub.model_download(\"kaggle/yolo-v5/tfLite/tflite-tflite-model\")\n",
    "print(\"Path to model files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to .tflite model file\n",
    "model_path = path+'/1.tflite'\n",
    "# Get the size of the .tflite file\n",
    "model_size = os.path.getsize(model_path)\n",
    "# Convert size to megabytes\n",
    "model_size_mb = model_size / (1024 ** 2)\n",
    "print(f\"Size of the model: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same to above\n",
    "def checkModelSize(path):\n",
    "    size = os.path.getsize(path) / (1024 ** 2)\n",
    "    print(f\"Size of the model: {size:.2f} MB\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Train your own .tflite models\n",
    "Supported frameworks:\n",
    "1. TensorFlow: https://ai.google.dev/edge/litert/models/convert_tf\n",
    "2. PyTorch: https://ai.google.dev/edge/litert/models/convert_pytorch\n",
    "3. JAX: https://ai.google.dev/edge/litert/models/convert_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Model explorer\n",
    "\n",
    "Supported model formats: TF (.pb, .pbtxt, .graphdef), TFLite (.tflite), TFJS (.json), JAX (.pb), PyTorch ExportedProgram (.pt2), MLIR (.mlir, .mlirbc). \n",
    "\n",
    "link: https://github.com/google-ai-edge/model-explorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ai-edge-model-explorer\n",
    "!model-explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
